"""
Twitterå†…å®¹åˆ†ææ¨¡å—
ä½¿ç”¨LLMåˆ†ææ¨æ–‡çš„ç›¸å…³æ€§ï¼ˆä½¿ç”¨OpenAIå®˜æ–¹Python SDKï¼‰
"""
import asyncio
import httpx
from typing import List, Dict, Optional
from llm_client import LLMClient


class TwitterAnalyzer:
    """Twitterå†…å®¹åˆ†æå™¨"""

    def __init__(
        self,
        api_key: str,
        model: str = "gpt-4o",
        max_tokens: int = 4096,
        base_url: Optional[str] = None,
        max_concurrent: int = 5
    ):
        """
        åˆå§‹åŒ–åˆ†æå™¨

        Args:
            api_key: APIå¯†é’¥
            model: æ¨¡å‹åç§°
            max_tokens: æœ€å¤§tokenæ•°
            base_url: è‡ªå®šä¹‰APIç«¯ç‚¹
            max_concurrent: æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
        """
        self.llm_client = LLMClient(
            api_key=api_key,
            base_url=base_url,
            model=model,
            max_tokens=max_tokens
        )
        self.max_concurrent = max_concurrent

    async def _call_api_async(self, prompt: str, client: httpx.AsyncClient, max_tokens: int = None) -> str:
        """è°ƒç”¨LLM API"""
        return await self.llm_client.chat_completion(
            prompt=prompt,
            client=client,
            max_tokens=max_tokens,
            temperature=0.7
        )

    async def analyze_tweets_async(self, tweets: List[Dict], research_interests: List[str] = None,
                                   research_prompt: str = None) -> List[Dict]:
        """
        å¼‚æ­¥åˆ†ææ¨æ–‡çš„ç›¸å…³æ€§

        Args:
            tweets: æ¨æ–‡åˆ—è¡¨
            research_interests: ç ”ç©¶æ–¹å‘åˆ—è¡¨
            research_prompt: ç ”ç©¶å…´è¶£æè¿°

        Returns:
            å¸¦æœ‰åˆ†æç»“æœçš„æ¨æ–‡åˆ—è¡¨
        """
        if not tweets:
            return []

        print(f"\næ­£åœ¨åˆ†æ {len(tweets)} æ¡æ¨æ–‡çš„ç›¸å…³æ€§...")

        # æ„å»ºç ”ç©¶æ–¹å‘æè¿°
        if research_prompt:
            research_description = f"ç”¨æˆ·çš„ç ”ç©¶å…´è¶£ï¼š\n{research_prompt}"
        else:
            research_description = f"ç”¨æˆ·çš„ç ”ç©¶æ–¹å‘ï¼š{', '.join(research_interests)}"

        semaphore = asyncio.Semaphore(self.max_concurrent)

        async with httpx.AsyncClient(
            limits=httpx.Limits(max_connections=self.max_concurrent * 2,
                              max_keepalive_connections=self.max_concurrent),
            timeout=httpx.Timeout(60.0, connect=10.0)
        ) as client:
            # åˆ†æ‰¹å¤„ç†ï¼ˆæ¯æ‰¹10æ¡ï¼‰
            batch_size = 10
            batches = []
            for i in range(0, len(tweets), batch_size):
                batch = tweets[i:min(i + batch_size, len(tweets))]
                batches.append(batch)

            print(f"åˆ†ä¸º {len(batches)} ä¸ªæ‰¹æ¬¡è¿›è¡Œåˆ†æ...\n")

            tasks = [
                self._analyze_tweet_batch_async(batch, research_description, client, semaphore)
                for batch in batches
            ]

            all_results = []
            for i, task in enumerate(asyncio.as_completed(tasks), 1):
                results = await task
                all_results.extend(results)
                print(f"  [{i}/{len(batches)}] âœ“ å®Œæˆæ‰¹æ¬¡ {i}")

        # åˆå¹¶åˆ†æç»“æœåˆ°æ¨æ–‡
        for i, tweet in enumerate(tweets):
            if i < len(all_results):
                tweet.update(all_results[i])

        # è¿‡æ»¤ç›¸å…³æ¨æ–‡
        relevant_tweets = [t for t in tweets if t.get('is_relevant', False)]

        print(f"\nâœ… åˆ†æå®Œæˆï¼")
        print(f"   - æ€»æ¨æ–‡æ•°: {len(tweets)}")
        print(f"   - ç›¸å…³æ¨æ–‡: {len(relevant_tweets)}")

        high_rel = sum(1 for t in tweets if t.get('relevance_level') == 'high')
        medium_rel = sum(1 for t in tweets if t.get('relevance_level') == 'medium')
        print(f"   - é«˜ç›¸å…³: {high_rel}")
        print(f"   - ä¸­ç›¸å…³: {medium_rel}")

        return tweets

    async def _analyze_tweet_batch_async(self, tweets_batch: List[Dict], research_description: str,
                                        client: httpx.AsyncClient, semaphore: asyncio.Semaphore) -> List[Dict]:
        """æ‰¹é‡åˆ†ææ¨æ–‡"""
        async with semaphore:
            # æ„å»ºæ‰¹é‡åˆ†ææç¤ºè¯
            tweets_text = ""
            for i, tweet in enumerate(tweets_batch):
                tweets_text += f"\nã€æ¨æ–‡{i}ã€‘\n"
                tweets_text += f"ä½œè€…: @{tweet['author_username']} ({tweet['author_name']})\n"
                tweets_text += f"ç²‰ä¸æ•°: {tweet['author_followers']}\n"
                tweets_text += f"å†…å®¹: {tweet['text']}\n"
                tweets_text += f"äº’åŠ¨: ğŸ‘{tweet['favorite_count']} ğŸ”„{tweet['retweet_count']} ğŸ’¬{tweet['reply_count']}\n"

            prompt = f"""ä½ æ˜¯ä¸€ä¸ªAIç ”ç©¶åŠ©æ‰‹ã€‚è¯·åˆ¤æ–­ä»¥ä¸‹Twitteræ¨æ–‡æ˜¯å¦ä¸ç”¨æˆ·çš„ç ”ç©¶æ–¹å‘ç›¸å…³ã€‚

{research_description}

{tweets_text}

è¯·å¯¹æ¯æ¡æ¨æ–‡æŒ‰ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š

ã€æ¨æ–‡Xã€‘ç›¸å…³æ€§: é«˜/ä¸­/ä½/æ— å…³  |  åŸå› : XXXï¼ˆ1-2å¥è¯è¯´æ˜ä¸ºä»€ä¹ˆç›¸å…³æˆ–ä¸ç›¸å…³ï¼‰

æ³¨æ„ï¼š
- å¿…é¡»åŒ…å«ã€æ¨æ–‡Xã€‘æ ‡è®°
- æŠ€æœ¯è®¨è®ºã€è®ºæ–‡åˆ†äº«ã€ä¼šè®®ä¿¡æ¯ã€ç ”ç©¶åŠ¨æ€éƒ½å¯èƒ½ç›¸å…³
- ä¸šç•Œæ–°é—»å¦‚æœä¸ç ”ç©¶æ–¹å‘ç›¸å…³ä¹Ÿç®—ç›¸å…³"""

            try:
                response_text = await self._call_api_async(prompt, client, max_tokens=2048)

                # è§£æå“åº”
                results = []
                lines = response_text.strip().split('\n')

                for line in lines:
                    line = line.strip()
                    if 'ã€æ¨æ–‡' in line and 'ã€‘' in line:
                        try:
                            # æå–æ¨æ–‡ç¼–å·
                            tweet_idx = int(line.split('ã€æ¨æ–‡')[1].split('ã€‘')[0])

                            # æå–ç›¸å…³æ€§
                            relevance = 'none'
                            if 'ç›¸å…³æ€§' in line:
                                if 'é«˜' in line.split('ç›¸å…³æ€§')[1].split('|')[0]:
                                    relevance = 'high'
                                elif 'ä¸­' in line.split('ç›¸å…³æ€§')[1].split('|')[0]:
                                    relevance = 'medium'
                                elif 'ä½' in line.split('ç›¸å…³æ€§')[1].split('|')[0]:
                                    relevance = 'low'

                            # æå–åŸå› 
                            reason = ''
                            if 'åŸå› ' in line:
                                reason = line.split('åŸå› :')[-1].strip()

                            results.append({
                                'relevance_level': relevance,
                                'is_relevant': relevance in ['high', 'medium'],
                                'relevance_reason': reason
                            })

                        except (ValueError, IndexError) as e:
                            results.append({
                                'relevance_level': 'unknown',
                                'is_relevant': False,
                                'relevance_reason': 'è§£æå¤±è´¥'
                            })

                # ç¡®ä¿ç»“æœæ•°é‡ä¸æ¨æ–‡æ•°é‡ä¸€è‡´
                while len(results) < len(tweets_batch):
                    results.append({
                        'relevance_level': 'unknown',
                        'is_relevant': False,
                        'relevance_reason': 'æœªåˆ†æ'
                    })

                return results

            except Exception as e:
                print(f"  âš ï¸  æ‰¹é‡åˆ†ææ¨æ–‡æ—¶å‡ºé”™: {e}")
                return [{
                    'relevance_level': 'unknown',
                    'is_relevant': False,
                    'relevance_reason': f'åˆ†æå¤±è´¥: {e}'
                } for _ in tweets_batch]
