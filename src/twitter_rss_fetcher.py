"""
Twitter RSSè·å–æ¨¡å—ï¼ˆåŸºäºNitterï¼‰
å®Œå…¨å…è´¹ï¼Œæ— éœ€APIï¼Œæ— éœ€çˆ¬è™«
"""
import feedparser
import requests
from typing import List, Dict
from datetime import datetime, timedelta
import time


class TwitterRSSFetcher:
    """ä½¿ç”¨Nitter RSSè·å–Twitterå†…å®¹ï¼ˆæœ€ç¨³å®šçš„å…è´¹æ–¹æ¡ˆï¼‰"""

    # Nitterå…¬å…±å®ä¾‹åˆ—è¡¨ï¼ˆå¦‚æœä¸€ä¸ªå¤±è´¥ä¼šè‡ªåŠ¨å°è¯•ä¸‹ä¸€ä¸ªï¼‰
    NITTER_INSTANCES = [
        'https://nitter.net',
        'https://nitter.privacydev.net',
        'https://nitter.poast.org',
        'https://nitter.1d4.us',
    ]

    def __init__(self, timeout: int = 10):
        """
        åˆå§‹åŒ–Twitter RSSè·å–å™¨

        Args:
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.timeout = timeout
        self.working_instance = None

    def _find_working_instance(self) -> str:
        """æ‰¾åˆ°ä¸€ä¸ªå¯ç”¨çš„Nitterå®ä¾‹"""
        if self.working_instance:
            return self.working_instance

        print("  ğŸ” å¯»æ‰¾å¯ç”¨çš„Nitterå®ä¾‹...")
        for instance in self.NITTER_INSTANCES:
            try:
                response = requests.get(f"{instance}/elonmusk/rss", timeout=5)
                if response.status_code == 200:
                    self.working_instance = instance
                    print(f"  âœ… ä½¿ç”¨å®ä¾‹: {instance}")
                    return instance
            except:
                continue

        raise Exception("æ‰€æœ‰Nitterå®ä¾‹éƒ½ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•")

    def get_user_tweets(self, username: str, max_results: int = 10, days_back: int = 7) -> List[Dict]:
        """
        è·å–æŒ‡å®šç”¨æˆ·çš„æœ€è¿‘æ¨æ–‡

        Args:
            username: Twitterç”¨æˆ·åï¼ˆä¸å«@ï¼‰
            max_results: æœ€å¤šè·å–å¤šå°‘æ¡
            days_back: è·å–æœ€è¿‘å‡ å¤©çš„æ¨æ–‡

        Returns:
            æ¨æ–‡åˆ—è¡¨
        """
        try:
            instance = self._find_working_instance()
            rss_url = f"{instance}/{username}/rss"

            # è·å–RSS feed
            feed = feedparser.parse(rss_url)

            if not feed.entries:
                return []

            # è®¡ç®—æ—¶é—´èŒƒå›´
            cutoff_date = datetime.now() - timedelta(days=days_back)

            # è§£ææ¨æ–‡
            tweets = []
            for entry in feed.entries[:max_results]:
                # è§£æå‘å¸ƒæ—¶é—´
                pub_date = None
                if hasattr(entry, 'published_parsed') and entry.published_parsed:
                    pub_date = datetime(*entry.published_parsed[:6])
                elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:
                    pub_date = datetime(*entry.updated_parsed[:6])

                # è¿‡æ»¤æ—¶é—´èŒƒå›´
                if pub_date and pub_date < cutoff_date:
                    continue

                # æå–æ¨æ–‡å†…å®¹
                text = entry.get('title', '') or entry.get('summary', '')
                # æ¸…ç†HTMLæ ‡ç­¾
                if text:
                    import re
                    text = re.sub(r'<[^>]+>', '', text)
                    text = re.sub(r'https?://\S+', '', text)  # ç§»é™¤é“¾æ¥
                    text = text.strip()

                if not text:
                    continue

                tweets.append({
                    'id': entry.get('id', ''),
                    'text': text,
                    'created_at': pub_date.strftime('%Y-%m-%d %H:%M:%S') if pub_date else '',
                    'url': entry.get('link', ''),
                    'author_username': username,
                    'author_name': username,
                    'favorite_count': 0,  # RSSä¸æä¾›
                    'retweet_count': 0,   # RSSä¸æä¾›
                    'reply_count': 0,     # RSSä¸æä¾›
                    'source_type': 'nitter_rss'
                })

            return tweets

        except Exception as e:
            print(f"  âŒ è·å– @{username} å¤±è´¥: {e}")
            return []

    def get_tweets_from_list(self, usernames: List[str], tweets_per_user: int = 5,
                            days_back: int = 7) -> List[Dict]:
        """
        ä»å¤šä¸ªç”¨æˆ·è·å–æ¨æ–‡

        Args:
            usernames: ç”¨æˆ·ååˆ—è¡¨
            tweets_per_user: æ¯ä¸ªç”¨æˆ·è·å–çš„æ¨æ–‡æ•°
            days_back: è·å–æœ€è¿‘å‡ å¤©çš„æ¨æ–‡

        Returns:
            æ‰€æœ‰æ¨æ–‡åˆ—è¡¨
        """
        print(f"\nğŸ“± æ­£åœ¨ä» {len(usernames)} ä¸ª Twitter è´¦å·è·å–æ¨æ–‡ï¼ˆRSSï¼‰...")
        print(f"æ¯ä¸ªè´¦å·è·å–æœ€å¤š {tweets_per_user} æ¡æ¨æ–‡ï¼ˆæœ€è¿‘{days_back}å¤©ï¼‰\n")

        all_tweets = []
        for i, username in enumerate(usernames, 1):
            print(f"  [{i}/{len(usernames)}] ğŸ“¥ @{username}...", end=' ')
            tweets = self.get_user_tweets(username, tweets_per_user, days_back)

            if tweets:
                all_tweets.extend(tweets)
                print(f"âœ… {len(tweets)}æ¡")
            else:
                print("âŒ")

            # é¿å…è¯·æ±‚è¿‡å¿«
            if i < len(usernames):
                time.sleep(1)

        print(f"\nâœ… æ€»å…±è·å– {len(all_tweets)} æ¡æ¨æ–‡")
        return all_tweets


# æ¨èçš„å­¦æœ¯Twitterè´¦å·
RECOMMENDED_ACCOUNTS = {
    'ai_research': [
        '_akhaliq',       # AI Papers Dailyï¼ˆæ¯æ—¥AIè®ºæ–‡æ›´æ–°ï¼Œå¼ºçƒˆæ¨èï¼‰
        'labmlai',        # LabML.aiï¼ˆMLè®ºæ–‡è§£æï¼‰
        'paperswithcode', # Papers with Code
    ],
    'researchers': [
        'karpathy',       # Andrej Karpathyï¼ˆå‰Tesla AIä¸»ç®¡ï¼‰
        'hardmaru',       # David Haï¼ˆVLMã€ç”Ÿæˆæ¨¡å‹ï¼‰
        'ylecun',         # Yann LeCunï¼ˆæ·±åº¦å­¦ä¹ å…ˆé©±ï¼‰
        'goodfellow_ian', # Ian Goodfellowï¼ˆGANå‘æ˜è€…ï¼‰
    ],
    'autonomous_driving': [
        'DrJimFan',       # Jim Fanï¼ˆNVIDIAï¼Œå…·èº«æ™ºèƒ½ï¼‰
        'Comma_ai',       # Comma.aiï¼ˆå¼€æºè‡ªåŠ¨é©¾é©¶ï¼‰
    ],
    'embodied_ai': [
        'hausman_k',      # Karol Hausmanï¼ˆGoogleï¼Œæœºå™¨äººï¼‰
        'chelseabfinn',   # Chelsea Finnï¼ˆStanfordï¼Œå…ƒå­¦ä¹ ï¼‰
    ]
}


if __name__ == '__main__':
    # æµ‹è¯•ä»£ç 
    fetcher = TwitterRSSFetcher()

    # æµ‹è¯•è·å–å•ä¸ªç”¨æˆ·
    print("=" * 60)
    print("æµ‹è¯•Twitter RSSè·å–åŠŸèƒ½")
    print("=" * 60)

    test_users = ['_akhaliq', 'karpathy']
    tweets = fetcher.get_tweets_from_list(test_users, tweets_per_user=3, days_back=1)

    if tweets:
        print(f"\nğŸ“ ç¤ºä¾‹æ¨æ–‡ï¼š")
        for i, tweet in enumerate(tweets[:5], 1):
            print(f"\n{i}. @{tweet['author_username']}")
            print(f"   æ—¶é—´: {tweet['created_at']}")
            print(f"   å†…å®¹: {tweet['text'][:150]}...")
            print(f"   é“¾æ¥: {tweet['url']}")
    else:
        print("\nâš ï¸  æœªè·å–åˆ°æ¨æ–‡ï¼Œå¯èƒ½Nitterå®ä¾‹æš‚æ—¶ä¸å¯ç”¨")
