"""
Twitterå…è´¹çˆ¬è™«æ¨¡å—ï¼ˆåŸºäºsnscrapeï¼‰
æ— éœ€APIå¯†é’¥ï¼Œå®Œå…¨å…è´¹
"""
import subprocess
import json
from typing import List, Dict
from datetime import datetime, timedelta


class TwitterScraper:
    """ä½¿ç”¨snscrapeçˆ¬å–Twitterå†…å®¹ï¼ˆæ— éœ€APIï¼‰"""

    def __init__(self):
        """åˆå§‹åŒ–Twitterçˆ¬è™«"""
        self.check_snscrape_installed()

    def check_snscrape_installed(self):
        """æ£€æŸ¥snscrapeæ˜¯å¦å·²å®‰è£…"""
        try:
            subprocess.run(['snscrape', '--version'],
                         capture_output=True,
                         check=True,
                         timeout=5)
        except (subprocess.CalledProcessError, FileNotFoundError):
            print("\nâš ï¸  snscrapeæœªå®‰è£…ï¼Œæ­£åœ¨å®‰è£…...")
            print("è¿è¡Œï¼špip install snscrape")
            raise ImportError("è¯·å…ˆå®‰è£…snscrape: pip install snscrape")

    def get_user_tweets(self, username: str, max_results: int = 10, days_back: int = 7) -> List[Dict]:
        """
        è·å–æŒ‡å®šç”¨æˆ·çš„æœ€è¿‘æ¨æ–‡

        Args:
            username: Twitterç”¨æˆ·åï¼ˆä¸å«@ï¼‰
            max_results: æœ€å¤šè·å–å¤šå°‘æ¡
            days_back: è·å–æœ€è¿‘å‡ å¤©çš„æ¨æ–‡

        Returns:
            æ¨æ–‡åˆ—è¡¨
        """
        try:
            # è®¡ç®—æ—¥æœŸèŒƒå›´
            since_date = (datetime.now() - timedelta(days=days_back)).strftime('%Y-%m-%d')

            # æ„å»ºsnscrapeå‘½ä»¤
            # ä½¿ç”¨TwitterUserScraperè·å–ç”¨æˆ·æ¨æ–‡
            cmd = [
                'snscrape',
                '--jsonl',  # è¾“å‡ºJSON Linesæ ¼å¼
                '--max-results', str(max_results),
                '--since', since_date,
                f'twitter-user:{username}'
            ]

            # æ‰§è¡Œå‘½ä»¤
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=30,
                check=True
            )

            # è§£æJSON Linesè¾“å‡º
            tweets = []
            for line in result.stdout.strip().split('\n'):
                if not line:
                    continue
                try:
                    tweet_data = json.loads(line)
                    tweets.append({
                        'id': tweet_data.get('id', ''),
                        'text': tweet_data.get('content', ''),
                        'created_at': tweet_data.get('date', ''),
                        'url': tweet_data.get('url', ''),
                        'author_username': username,
                        'author_name': tweet_data.get('user', {}).get('displayname', username),
                        'favorite_count': tweet_data.get('likeCount', 0),
                        'retweet_count': tweet_data.get('retweetCount', 0),
                        'reply_count': tweet_data.get('replyCount', 0),
                        'source_type': 'snscrape'
                    })
                except json.JSONDecodeError:
                    continue

            return tweets

        except subprocess.TimeoutExpired:
            print(f"  âš ï¸  è·å– @{username} è¶…æ—¶")
            return []
        except subprocess.CalledProcessError as e:
            print(f"  âŒ è·å– @{username} å¤±è´¥: {e.stderr}")
            return []
        except Exception as e:
            print(f"  âŒ æ„å¤–é”™è¯¯: {str(e)}")
            return []

    def get_tweets_from_list(self, usernames: List[str], tweets_per_user: int = 5,
                            days_back: int = 7) -> List[Dict]:
        """
        ä»å¤šä¸ªç”¨æˆ·è·å–æ¨æ–‡

        Args:
            usernames: ç”¨æˆ·ååˆ—è¡¨
            tweets_per_user: æ¯ä¸ªç”¨æˆ·è·å–çš„æ¨æ–‡æ•°
            days_back: è·å–æœ€è¿‘å‡ å¤©çš„æ¨æ–‡

        Returns:
            æ‰€æœ‰æ¨æ–‡åˆ—è¡¨
        """
        print(f"\nğŸ“± æ­£åœ¨ä» {len(usernames)} ä¸ª Twitter è´¦å·çˆ¬å–æ¨æ–‡...")
        print(f"æ¯ä¸ªè´¦å·è·å–æœ€å¤š {tweets_per_user} æ¡æ¨æ–‡ï¼ˆæœ€è¿‘{days_back}å¤©ï¼‰\n")

        all_tweets = []
        for username in usernames:
            print(f"  ğŸ“¥ æŠ“å– @{username}...", end=' ')
            tweets = self.get_user_tweets(username, tweets_per_user, days_back)

            if tweets:
                all_tweets.extend(tweets)
                print(f"âœ… è·å– {len(tweets)} æ¡")
            else:
                print("âŒ å¤±è´¥")

        print(f"\nâœ… æ€»å…±è·å– {len(all_tweets)} æ¡æ¨æ–‡")
        return all_tweets


# æ¨èçš„å­¦æœ¯Twitterè´¦å·
RECOMMENDED_ACCOUNTS = {
    'ai_research': [
        '_akhaliq',       # AI Papers Dailyï¼ˆæ¯æ—¥AIè®ºæ–‡æ›´æ–°ï¼‰
        'labmlai',        # LabML.aiï¼ˆMLè®ºæ–‡è§£æï¼‰
        'paperswithcode', # Papers with Code
    ],
    'researchers': [
        'karpathy',       # Andrej Karpathyï¼ˆå‰Tesla AIä¸»ç®¡ï¼‰
        'hardmaru',       # David Haï¼ˆVLMã€ç”Ÿæˆæ¨¡å‹ï¼‰
        'ylecun',         # Yann LeCunï¼ˆæ·±åº¦å­¦ä¹ å…ˆé©±ï¼‰
        'goodfellow_ian', # Ian Goodfellowï¼ˆGANå‘æ˜è€…ï¼‰
    ],
    'autonomous_driving': [
        'DrJimFan',       # Jim Fanï¼ˆNVIDIAï¼Œå…·èº«æ™ºèƒ½ï¼‰
        'Comma_ai',       # Comma.aiï¼ˆå¼€æºè‡ªåŠ¨é©¾é©¶ï¼‰
    ],
    'embodied_ai': [
        'hausman_k',      # Karol Hausmanï¼ˆGoogleï¼Œæœºå™¨äººï¼‰
        'chelseabfinn',   # Chelsea Finnï¼ˆStanfordï¼Œå…ƒå­¦ä¹ ï¼‰
    ]
}


if __name__ == '__main__':
    # æµ‹è¯•ä»£ç 
    scraper = TwitterScraper()

    # æµ‹è¯•è·å–å•ä¸ªç”¨æˆ·
    test_users = ['_akhaliq', 'karpathy']
    tweets = scraper.get_tweets_from_list(test_users, tweets_per_user=3, days_back=3)

    if tweets:
        print(f"\nç¤ºä¾‹æ¨æ–‡ï¼š")
        for i, tweet in enumerate(tweets[:3], 1):
            print(f"\n{i}. @{tweet['author_username']}: {tweet['text'][:100]}...")
            print(f"   â¤ï¸  {tweet['favorite_count']} | ğŸ”„ {tweet['retweet_count']}")
