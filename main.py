#!/usr/bin/env python3
"""
ArXiv Agent - è‡ªåŠ¨æœç´¢å’Œåˆ†æArXivè®ºæ–‡

ä½¿ç”¨æ–¹æ³•:
    python main.py [é€‰é¡¹]

é€‰é¡¹:
    --config PATH       é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config.yaml)
    --days N           æœç´¢æœ€è¿‘Nå¤©çš„è®ºæ–‡ (è¦†ç›–é…ç½®æ–‡ä»¶)
    --no-analysis      ä»…æœç´¢ï¼Œä¸è¿›è¡ŒAIåˆ†æ
    --min-relevance    æœ€å°ç›¸å…³æ€§çº§åˆ«: high/medium/low (é»˜è®¤: medium)
    --max-concurrent   æœ€å¤§å¹¶å‘è¯·æ±‚æ•° (é»˜è®¤: 5)
    --help             æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
"""
import os
import sys
import asyncio
import argparse
from dotenv import load_dotenv

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from config_loader import ConfigLoader
from arxiv_searcher import ArxivSearcher
from llm_analyzer import LLMAnalyzer
from report_generator import ReportGenerator
from email_sender import EmailSender


def main():
    """ä¸»å‡½æ•°"""
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='ArXiv Agent - è‡ªåŠ¨æœç´¢å’Œåˆ†æArXivè®ºæ–‡')
    parser.add_argument('--config', type=str, default='config.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--days', type=int, help='æœç´¢æœ€è¿‘Nå¤©çš„è®ºæ–‡')
    parser.add_argument('--no-analysis', action='store_true', help='ä»…æœç´¢ï¼Œä¸è¿›è¡ŒAIåˆ†æ')
    parser.add_argument('--min-relevance', type=str,
                        choices=['high', 'medium', 'low'],
                        help='æœ€å°ç›¸å…³æ€§çº§åˆ«ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰')
    parser.add_argument('--max-concurrent', type=int, default=5,
                        help='æœ€å¤§å¹¶å‘è¯·æ±‚æ•°ï¼ˆé»˜è®¤: 5ï¼‰')

    args = parser.parse_args()

    try:
        # åŠ è½½é…ç½®
        print("=" * 60)
        print("ArXiv Agent - è®ºæ–‡æœç´¢ä¸åˆ†æ")
        print("=" * 60)
        print(f"\næ­£åœ¨åŠ è½½é…ç½®æ–‡ä»¶: {args.config}")

        config = ConfigLoader(args.config)

        research_interests = config.get_research_interests()
        arxiv_categories = config.get_arxiv_categories()
        max_results = config.get_max_results()
        days_back = args.days if args.days else config.get_days_back()
        output_dir = config.get_output_dir()
        min_relevance_config = config.get_min_relevance()

        print(f"ç ”ç©¶æ–¹å‘: {', '.join(research_interests)}")
        print(f"ArXivç±»åˆ«: {', '.join(arxiv_categories)}")
        print(f"æœç´¢æœ€è¿‘ {days_back} å¤©çš„è®ºæ–‡")
        print(f"æœ€å¤§ç»“æœæ•°: {max_results}")
        relevance_label = {'high': 'é«˜', 'medium': 'ä¸­', 'low': 'ä½'}.get(min_relevance_config, min_relevance_config)
        print(f"ç›¸å…³æ€§é˜ˆå€¼: {relevance_label}ç›¸å…³åŠä»¥ä¸Š")

        # 1. æœç´¢è®ºæ–‡
        print(f"\n{'=' * 60}")
        print("æ­¥éª¤ 1: æœç´¢ArXivè®ºæ–‡")
        print("=" * 60)

        searcher = ArxivSearcher(
            categories=arxiv_categories,
            max_results=max_results
        )

        papers = searcher.search_recent_papers(days_back=days_back)

        if not papers:
            print("æœªæ‰¾åˆ°ä»»ä½•è®ºæ–‡ã€‚")
            return

        print(f"æ‰¾åˆ° {len(papers)} ç¯‡è®ºæ–‡")

        # 2. åˆ†æè®ºæ–‡ï¼ˆå¯é€‰ï¼‰
        if not args.no_analysis:
            print(f"\n{'=' * 60}")
            print("æ­¥éª¤ 2: ä½¿ç”¨Claudeåˆ†æè®ºæ–‡ç›¸å…³æ€§")
            print("=" * 60)

            # è·å–APIé…ç½®ï¼ˆä¼˜å…ˆä»config.yamlï¼Œç„¶åä».envï¼‰
            api_key = config.get_api_key() or os.getenv('ANTHROPIC_AUTH_TOKEN') or os.getenv('ANTHROPIC_API_KEY')
            api_base_url = config.get_api_base_url() or os.getenv('ANTHROPIC_BASE_URL')

            if not api_key:
                print("é”™è¯¯: æœªæ‰¾åˆ°APIå¯†é’¥")
                print("è¯·åœ¨config.yamlä¸­è®¾ç½®api_keyï¼Œæˆ–åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®ANTHROPIC_AUTH_TOKEN")
                return

            # è·å–å¹¶å‘é…ç½®ï¼ˆå‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®æ–‡ä»¶ï¼‰
            max_concurrent = args.max_concurrent if args.max_concurrent != 5 else config.get_max_concurrent()

            analyzer = LLMAnalyzer(
                api_key=api_key,
                model=config.get_claude_model(),
                max_tokens=config.get_claude_max_tokens(),
                base_url=api_base_url,
                max_concurrent=max_concurrent,
                batch_size=config.get_batch_size(),
                detail_batch_size=config.get_detail_batch_size()
            )

            # ä½¿ç”¨ä¸¤é˜¶æ®µå¼‚æ­¥åˆ†æï¼ˆå¿«é€Ÿç­›é€‰ + è¯¦ç»†åˆ†æï¼‰
            analyzed_papers = asyncio.run(
                analyzer.two_stage_analyze_papers_async(papers, research_interests)
            )

            # è·å–ç›¸å…³æ€§é˜ˆå€¼ï¼ˆå‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®æ–‡ä»¶ï¼‰
            min_relevance = args.min_relevance if args.min_relevance else config.get_min_relevance()

            # è¿‡æ»¤ç›¸å…³è®ºæ–‡
            relevant_papers = analyzer.filter_relevant_papers(
                analyzed_papers,
                min_relevance=min_relevance
            )

            relevance_label = {'high': 'é«˜', 'medium': 'ä¸­', 'low': 'ä½'}.get(min_relevance, min_relevance)
            print(f"\næ ¹æ®é˜ˆå€¼ï¼ˆ{relevance_label}ç›¸å…³åŠä»¥ä¸Šï¼‰æ‰¾åˆ° {len(relevant_papers)} ç¯‡ç›¸å…³è®ºæ–‡")

            papers_to_report = relevant_papers
        else:
            print("\nè·³è¿‡AIåˆ†æ")
            papers_to_report = papers

        # 3. ç”ŸæˆæŠ¥å‘Š
        print(f"\n{'=' * 60}")
        print("æ­¥éª¤ 3: ç”ŸæˆæŠ¥å‘Š")
        print("=" * 60)

        generator = ReportGenerator(output_dir=output_dir)
        report_path = generator.generate_report(papers_to_report, research_interests)

        print(f"\n{'=' * 60}")
        print("å®Œæˆ!")
        print("=" * 60)
        print(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
        print(f"æ€»è®ºæ–‡æ•°: {len(papers)}")
        if not args.no_analysis:
            print(f"ç›¸å…³è®ºæ–‡æ•°: {len(papers_to_report)}")

        # 4. å‘é€é‚®ä»¶ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if config.is_email_enabled():
            print(f"\n{'=' * 60}")
            print("æ­¥éª¤ 4: å‘é€é‚®ä»¶é€šçŸ¥")
            print("=" * 60)

            email_config = config.get_email_config()

            try:
                sender = EmailSender(
                    smtp_server=email_config.get('smtp_server'),
                    smtp_port=email_config.get('smtp_port', 587),
                    sender_email=email_config.get('sender_email'),
                    sender_password=email_config.get('sender_password'),
                    use_ssl=email_config.get('use_ssl', False)
                )

                # æ”¶ä»¶äººé‚®ç®±ï¼ˆæ”¯æŒå¤šä¸ªï¼Œç”¨é€—å·åˆ†éš”ï¼‰
                receiver_str = email_config.get('receiver_email', '')
                receiver_emails = [email.strip() for email in receiver_str.split(',') if email.strip()]

                if not receiver_emails:
                    print("âš ï¸  æœªé…ç½®æ”¶ä»¶äººé‚®ç®±ï¼Œè·³è¿‡é‚®ä»¶å‘é€")
                else:
                    # æ„å»ºé‚®ä»¶ä¸»é¢˜
                    from datetime import datetime
                    subject_prefix = email_config.get('subject_prefix', '[ArXivæ¯æ—¥è®ºæ–‡]')
                    subject = f"{subject_prefix} {datetime.now().strftime('%Y-%m-%d')}"

                    # æ„å»ºé‚®ä»¶æ‘˜è¦
                    if not args.no_analysis:
                        summary = f"""ä»Šæ—¥ArXivè®ºæ–‡åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆï¼

ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š
- æ€»è®ºæ–‡æ•°: {len(papers)} ç¯‡
- ç›¸å…³è®ºæ–‡æ•°: {len(papers_to_report)} ç¯‡
  - é«˜ç›¸å…³: {sum(1 for p in papers_to_report if p.get('relevance_level') == 'high')} ç¯‡
  - ä¸­ç›¸å…³: {sum(1 for p in papers_to_report if p.get('relevance_level') == 'medium')} ç¯‡

ğŸ” ç ”ç©¶æ–¹å‘ï¼š
{chr(10).join(f'  - {interest}' for interest in research_interests)}

è¯¦ç»†å†…å®¹è¯·æŸ¥çœ‹é™„ä»¶æŠ¥å‘Šã€‚"""
                    else:
                        summary = f"""ä»Šæ—¥ArXivè®ºæ–‡æœç´¢å®Œæˆï¼

ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š
- æ€»è®ºæ–‡æ•°: {len(papers)} ç¯‡

è¯¦ç»†å†…å®¹è¯·æŸ¥çœ‹é™„ä»¶æŠ¥å‘Šã€‚"""

                    # å‘é€é‚®ä»¶
                    sender.send_report(
                        receiver_emails=receiver_emails,
                        subject=subject,
                        report_path=report_path,
                        summary=summary
                    )

            except Exception as e:
                print(f"âŒ é‚®ä»¶å‘é€é…ç½®é”™è¯¯: {e}")
                import traceback
                traceback.print_exc()

    except FileNotFoundError as e:
        print(f"é”™è¯¯: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
